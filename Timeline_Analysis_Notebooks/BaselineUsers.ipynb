{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Imports and includes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "from datetime import datetime as dt\n",
    "import matplotlib.pyplot as plt \n",
    "import pickle\n",
    "import statistics\n",
    "import numpy as np  \n",
    "import sys\n",
    "import glob\n",
    "\n",
    "pd.set_option('display.max_rows', 4000)\n",
    "pd.set_option('display.max_columns', 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langdetect import detect\n",
    "from langdetect import DetectorFactory\n",
    "DetectorFactory.seed = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "analyser = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sentiment analysis function provided by Upasana**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_analyzer_score_for_englishOnlyTweet(cleaned_tweet): #this function takes in a tweet that has been detected as an english tweet\n",
    "    score = analyser.polarity_scores(cleaned_tweet) #so this cleaned_tweet is always an english tweet.\n",
    "    lb = score['compound']\n",
    "    return lb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create list of all Baseline Users**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(glob.glob(\"/home/adam/*.txt\"))\n",
    "# df = pd.read_csv(\"/home/updu6059/BaselineUsers/FilteredBaselineUsers.csv\")\n",
    "df = pd.read_csv(\"/home/updu6059/BaselineUsers/FilteredBaselineUsers_2.csv\")\n",
    "# temp2D = pd.read_csv(, low_memory=False)\n",
    "\n",
    "# df = pd.read_csv('Filtered_EnglishUsers_DidnotMentionBackUsers.csv')\n",
    "UserList = list(df['Usernames'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of baseline users: 8023\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of baseline users: \" + str(len(UserList)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Functions to check for a mention of Donald Trump or Hillary Clinton in a tweet**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mentions_trump(mention_string):\n",
    "    if mention_string != \"[]\": \n",
    "        mention_list = mention_string.split(', ')\n",
    "        mention_list[0] = mention_list[0][1:]\n",
    "        mention_list[-1] = mention_list[-1][:-1]\n",
    "        for x in range(len(mention_list)):\n",
    "            mention_list[x] = mention_list[x][1:]\n",
    "            mention_list[x] = mention_list[x][:-1]\n",
    "        for x in range(len(mention_list)):\n",
    "            if mention_list[x] == 'realdonaldtrump':\n",
    "                return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mentions_clinton(mention_string):\n",
    "    if mention_string != \"[]\": \n",
    "        mention_list = mention_string.split(', ')\n",
    "        mention_list[0] = mention_list[0][1:]\n",
    "        mention_list[-1] = mention_list[-1][:-1]\n",
    "        for x in range(len(mention_list)):\n",
    "            mention_list[x] = mention_list[x][1:]\n",
    "            mention_list[x] = mention_list[x][:-1]\n",
    "        for x in range(len(mention_list)):\n",
    "            if mention_list[x] == 'hillaryclinton':\n",
    "                return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Calculate monthy values for each user (over the 96 months from Jan 2009 to December 2016)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "timelineDict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "firstTweetIndexDict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "timelineDF = pd.DataFrame(columns=['username','tweet_count','sentiment_scores', \n",
    "                                      'trump_count', 'clinton_count','trump_sent','clinton_sent',\n",
    "                                      'positive_sent', 'negative_sent'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 / 8023\n",
      "1 / 8023\n",
      "2 / 8023\n",
      "3 / 8023\n",
      "4 / 8023\n",
      "5 / 8023\n",
      "6 / 8023\n",
      "7 / 8023\n",
      "8 / 8023\n",
      "9 / 8023\n",
      "10 / 8023\n",
      "11 / 8023\n",
      "12 / 8023\n",
      "13 / 8023\n",
      "14 / 8023\n",
      "15 / 8023\n",
      "16 / 8023\n",
      "17 / 8023\n",
      "18 / 8023\n",
      "19 / 8023\n",
      "20 / 8023\n",
      "21 / 8023\n",
      "22 / 8023\n",
      "23 / 8023\n",
      "24 / 8023\n",
      "25 / 8023\n",
      "26 / 8023\n",
      "27 / 8023\n",
      "28 / 8023\n",
      "29 / 8023\n",
      "30 / 8023\n",
      "31 / 8023\n",
      "32 / 8023\n",
      "33 / 8023\n",
      "34 / 8023\n",
      "35 / 8023\n",
      "36 / 8023\n",
      "37 / 8023\n",
      "38 / 8023\n",
      "39 / 8023\n",
      "40 / 8023\n",
      "41 / 8023\n",
      "42 / 8023\n",
      "43 / 8023\n",
      "44 / 8023\n",
      "45 / 8023\n",
      "46 / 8023\n",
      "47 / 8023\n",
      "48 / 8023\n",
      "49 / 8023\n",
      "50 / 8023\n",
      "51 / 8023\n",
      "52 / 8023\n",
      "53 / 8023\n",
      "54 / 8023\n",
      "55 / 8023\n",
      "56 / 8023\n"
     ]
    }
   ],
   "source": [
    "size = str(len(UserList))\n",
    "for i in range(len(UserList)):\n",
    "# for i in range(100):\n",
    "    try:\n",
    "        #read in, reverse order (so oldest is first), reset index\n",
    "        temp_user_db = pd.read_csv('/home/ira-shared/BaselineUsers/'+UserList[i]+'_tweet_only.csv', low_memory=False)\n",
    "        temp_user_db = temp_user_db.iloc[::-1]\n",
    "        temp_user_db.reset_index(drop=True, inplace=True)\n",
    "        \n",
    "        #create lists for each metric\n",
    "        tweet_count = [\n",
    "            0,0,0,0,0,0,0,0,0,0,0,0,\n",
    "            0,0,0,0,0,0,0,0,0,0,0,0,\n",
    "            0,0,0,0,0,0,0,0,0,0,0,0,\n",
    "            0,0,0,0,0,0,0,0,0,0,0,0,\n",
    "            0,0,0,0,0,0,0,0,0,0,0,0,\n",
    "            0,0,0,0,0,0,0,0,0,0,0,0,\n",
    "            0,0,0,0,0,0,0,0,0,0,0,0,\n",
    "            0,0,0,0,0,0,0,0,0,0,0,0]\n",
    "        trump_count = [\n",
    "            0,0,0,0,0,0,0,0,0,0,0,0,\n",
    "            0,0,0,0,0,0,0,0,0,0,0,0,\n",
    "            0,0,0,0,0,0,0,0,0,0,0,0,\n",
    "            0,0,0,0,0,0,0,0,0,0,0,0,\n",
    "            0,0,0,0,0,0,0,0,0,0,0,0,\n",
    "            0,0,0,0,0,0,0,0,0,0,0,0,\n",
    "            0,0,0,0,0,0,0,0,0,0,0,0,\n",
    "            0,0,0,0,0,0,0,0,0,0,0,0]\n",
    "        clinton_count = [\n",
    "            0,0,0,0,0,0,0,0,0,0,0,0,\n",
    "            0,0,0,0,0,0,0,0,0,0,0,0,\n",
    "            0,0,0,0,0,0,0,0,0,0,0,0,\n",
    "            0,0,0,0,0,0,0,0,0,0,0,0,\n",
    "            0,0,0,0,0,0,0,0,0,0,0,0,\n",
    "            0,0,0,0,0,0,0,0,0,0,0,0,\n",
    "            0,0,0,0,0,0,0,0,0,0,0,0,\n",
    "            0,0,0,0,0,0,0,0,0,0,0,0]\n",
    "        sentiment_scores = [\n",
    "            [],[],[],[],[],[],[],[],[],[],[],[],\n",
    "            [],[],[],[],[],[],[],[],[],[],[],[],\n",
    "            [],[],[],[],[],[],[],[],[],[],[],[],\n",
    "            [],[],[],[],[],[],[],[],[],[],[],[],\n",
    "            [],[],[],[],[],[],[],[],[],[],[],[],\n",
    "            [],[],[],[],[],[],[],[],[],[],[],[],\n",
    "            [],[],[],[],[],[],[],[],[],[],[],[],\n",
    "            [],[],[],[],[],[],[],[],[],[],[],[]]\n",
    "        trump_sent = [\n",
    "            [],[],[],[],[],[],[],[],[],[],[],[],\n",
    "            [],[],[],[],[],[],[],[],[],[],[],[],\n",
    "            [],[],[],[],[],[],[],[],[],[],[],[],\n",
    "            [],[],[],[],[],[],[],[],[],[],[],[],\n",
    "            [],[],[],[],[],[],[],[],[],[],[],[],\n",
    "            [],[],[],[],[],[],[],[],[],[],[],[],\n",
    "            [],[],[],[],[],[],[],[],[],[],[],[],\n",
    "            [],[],[],[],[],[],[],[],[],[],[],[]]\n",
    "        clinton_sent = [\n",
    "            [],[],[],[],[],[],[],[],[],[],[],[],\n",
    "            [],[],[],[],[],[],[],[],[],[],[],[],\n",
    "            [],[],[],[],[],[],[],[],[],[],[],[],\n",
    "            [],[],[],[],[],[],[],[],[],[],[],[],\n",
    "            [],[],[],[],[],[],[],[],[],[],[],[],\n",
    "            [],[],[],[],[],[],[],[],[],[],[],[],\n",
    "            [],[],[],[],[],[],[],[],[],[],[],[],\n",
    "            [],[],[],[],[],[],[],[],[],[],[],[]]\n",
    "        positive_sent = [\n",
    "            [],[],[],[],[],[],[],[],[],[],[],[],\n",
    "            [],[],[],[],[],[],[],[],[],[],[],[],\n",
    "            [],[],[],[],[],[],[],[],[],[],[],[],\n",
    "            [],[],[],[],[],[],[],[],[],[],[],[],\n",
    "            [],[],[],[],[],[],[],[],[],[],[],[],\n",
    "            [],[],[],[],[],[],[],[],[],[],[],[],\n",
    "            [],[],[],[],[],[],[],[],[],[],[],[],\n",
    "            [],[],[],[],[],[],[],[],[],[],[],[]]\n",
    "        negative_sent = [\n",
    "            [],[],[],[],[],[],[],[],[],[],[],[],\n",
    "            [],[],[],[],[],[],[],[],[],[],[],[],\n",
    "            [],[],[],[],[],[],[],[],[],[],[],[],\n",
    "            [],[],[],[],[],[],[],[],[],[],[],[],\n",
    "            [],[],[],[],[],[],[],[],[],[],[],[],\n",
    "            [],[],[],[],[],[],[],[],[],[],[],[],\n",
    "            [],[],[],[],[],[],[],[],[],[],[],[],\n",
    "            [],[],[],[],[],[],[],[],[],[],[],[]]\n",
    "\n",
    "        #iterate through user tweets\n",
    "        first = 1\n",
    "        for j in range(len(temp_user_db)):\n",
    "\n",
    "            #step one is assigning an index for the tweet, based on date, or disregarding\n",
    "            found = 0\n",
    "            tweetdate = dt.strptime(temp_user_db['date'][j], \"%Y-%m-%d\")\n",
    "            for k in range(2009,2017):\n",
    "                temp_year = k\n",
    "                date_start = dt(temp_year,1,1)\n",
    "                date_end = dt(temp_year,12,31)\n",
    "                if tweetdate < date_start:\n",
    "                    continue;\n",
    "                elif tweetdate <= date_end:\n",
    "                    for m in range(2,14):\n",
    "                        if m == 13: #month must be December by process of elimination\n",
    "                            use_index = (((k-2009)*12)+(m-2))\n",
    "                            found = 1\n",
    "    #                         print(temp_user_db['date'][j] + \" \" +str(use_index))\n",
    "                            break;\n",
    "                        next_month_start = dt(temp_year,m,1)\n",
    "                        if tweetdate < next_month_start:\n",
    "                            use_index = (((k-2009)*12)+(m-2))\n",
    "                            found = 1\n",
    "    #                         print(temp_user_db['date'][j] + \" \" +str(use_index))\n",
    "                            break;\n",
    "\n",
    "            #tweet occurred within the period 2009-2016 and was assigned an valid index\n",
    "            if found == 1:\n",
    "                if first:\n",
    "                    firstTweetIndexDict[UserList[i]] = use_index\n",
    "                    first = 0\n",
    "                \n",
    "                tweet_count[use_index] +=1\n",
    "\n",
    "                tweet_sent = sentiment_analyzer_score_for_englishOnlyTweet(temp_user_db['tweet'][j])\n",
    "                sentiment_scores[use_index].append(tweet_sent)\n",
    "\n",
    "                trump_flag = mentions_trump(str(temp_user_db['mentions'][j]))\n",
    "                clinton_flag = mentions_clinton(str(temp_user_db['mentions'][j]))\n",
    "\n",
    "                if trump_flag: trump_count[use_index] += 1\n",
    "                if clinton_flag: clinton_count[use_index] += 1\n",
    "\n",
    "                if trump_flag and not clinton_flag: trump_sent[use_index].append(tweet_sent)\n",
    "                if clinton_flag and not trump_flag: clinton_sent[use_index].append(tweet_sent)\n",
    "\n",
    "                if tweet_sent > 0: positive_sent[use_index].append(tweet_sent)\n",
    "                if tweet_sent < 0: negative_sent[use_index].append(tweet_sent)\n",
    "\n",
    "        timelineDict[UserList[i]] = [tweet_count, sentiment_scores, trump_count, clinton_count, \n",
    "                                     trump_sent, clinton_sent, positive_sent, negative_sent]\n",
    "\n",
    "        print(str(i) + \" / \" + size)\n",
    "        \n",
    "    except Exception as e: \n",
    "        print(str(UserList[i]) + \" failed - \" + str(e))\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(firstTweetIndexDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(timelineDF)):\n",
    "    try:\n",
    "        test = firstTweetIndexDict[timelineDF['username'][i]]\n",
    "    except:\n",
    "        print(timelineDF['username'][i] + ' failed [' +str(i)+']' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timelineDF = pd.DataFrame.from_dict(timelineDict, orient='index',columns=['tweet_count','sentiment_scores', \n",
    "                                      'trump_count', 'clinton_count','trump_sent','clinton_sent',\n",
    "                                      'positive_sent', 'negative_sent'])\n",
    "\n",
    "timelineDF.index.name = 'username'\n",
    "timelineDF.reset_index(inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(timelineDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_countDict = {}\n",
    "sentiment_scoresDict = {}\n",
    "trump_countDict = {}\n",
    "clinton_countDict = {}\n",
    "trump_sentDict = {}\n",
    "clinton_sentDict = {}\n",
    "positive_sentDict = {}\n",
    "negative_sentDict = {} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "size = str(len(timelineDF))\n",
    "for i in range(len(timelineDF)):\n",
    "    start_index = firstTweetIndexDict[timelineDF['username'][i]]\n",
    "    \n",
    "    tweet_count = []\n",
    "    sentiment_scores = []\n",
    "    trump_count = []\n",
    "    clinton_count = []\n",
    "    trump_sent = []\n",
    "    clinton_sent = []\n",
    "    positive_sent = []\n",
    "    negative_sent = [] \n",
    "    \n",
    "    for j in range(0,96):\n",
    "        if j >= start_index:\n",
    "            tweet_count.append(timelineDF['tweet_count'][i][j])\n",
    "            trump_count.append(timelineDF['trump_count'][i][j])\n",
    "            clinton_count.append(timelineDF['clinton_count'][i][j])\n",
    "            \n",
    "            if(len(timelineDF['sentiment_scores'][i][j]) > 0):\n",
    "                sentiment_scores.append(statistics.mean(timelineDF['sentiment_scores'][i][j]))\n",
    "            else:\n",
    "                sentiment_scores.append(np.nan)\n",
    "            \n",
    "            if(len(timelineDF['trump_sent'][i][j]) > 0):\n",
    "                trump_sent.append(statistics.mean(timelineDF['trump_sent'][i][j]))\n",
    "            else:\n",
    "                trump_sent.append(np.nan)\n",
    "            \n",
    "            if(len(timelineDF['clinton_sent'][i][j]) > 0):\n",
    "                clinton_sent.append(statistics.mean(timelineDF['clinton_sent'][i][j]))\n",
    "            else:\n",
    "                clinton_sent.append(np.nan)\n",
    "                \n",
    "            if(len(timelineDF['positive_sent'][i][j]) > 0):\n",
    "                positive_sent.append(statistics.mean(timelineDF['positive_sent'][i][j]))\n",
    "            else:\n",
    "                positive_sent.append(np.nan)\n",
    "                \n",
    "            if(len(timelineDF['negative_sent'][i][j]) > 0):\n",
    "                negative_sent.append(statistics.mean(timelineDF['negative_sent'][i][j]))\n",
    "            else:\n",
    "                negative_sent.append(np.nan)\n",
    "                        \n",
    "        else:\n",
    "            tweet_count.append(np.nan)\n",
    "            trump_count.append(np.nan)\n",
    "            clinton_count.append(np.nan)\n",
    "            sentiment_scores.append(np.nan)\n",
    "            trump_sent.append(np.nan)\n",
    "            clinton_sent.append(np.nan)\n",
    "            positive_sent.append(np.nan)\n",
    "            negative_sent.append(np.nan)\n",
    "    \n",
    "    tweet_countDict[timelineDF['username'][i]] = tweet_count\n",
    "    sentiment_scoresDict[timelineDF['username'][i]] = sentiment_scores\n",
    "    trump_countDict[timelineDF['username'][i]] = trump_count\n",
    "    clinton_countDict[timelineDF['username'][i]] = clinton_count\n",
    "    trump_sentDict[timelineDF['username'][i]] = trump_sent\n",
    "    clinton_sentDict[timelineDF['username'][i]] = clinton_sent\n",
    "    positive_sentDict[timelineDF['username'][i]] = positive_sent\n",
    "    negative_sentDict[timelineDF['username'][i]] =  negative_sent \n",
    "    \n",
    "    print(str(i) + \" / \" + size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_countDF = pd.DataFrame.from_dict(tweet_countDict, orient='index',columns=['01-2009','02-2009','03-2009','04-2009','05-2009','06-2009','07-2009','08-2009','09-2009','10-2009','11-2009','12-2009',\n",
    "'01-2010','02-2010','03-2010','04-2010','05-2010','06-2010','07-2010','08-2010','09-2010','10-2010','11-2010','12-2010',\n",
    "'01-2011','02-2011','03-2011','04-2011','05-2011','06-2011','07-2011','08-2011','09-2011','10-2011','11-2011','12-2011',\n",
    "'01-2012','02-2012','03-2012','04-2012','05-2012','06-2012','07-2012','08-2012','09-2012','10-2012','11-2012','12-2012',\n",
    "'01-2013','02-2013','03-2013','04-2013','05-2013','06-2013','07-2013','08-2013','09-2013','10-2013','11-2013','12-2013',\n",
    "'01-2014','02-2014','03-2014','04-2014','05-2014','06-2014','07-2014','08-2014','09-2014','10-2014','11-2014','12-2014',\n",
    "'01-2015','02-2015','03-2015','04-2015','05-2015','06-2015','07-2015','08-2015','09-2015','10-2015','11-2015','12-2015',\n",
    "'01-2016','02-2016','03-2016','04-2016','05-2016','06-2016','07-2016','08-2016','09-2016','10-2016','11-2016','12-2016'])\n",
    "tweet_countDF.index.name = 'username'\n",
    "tweet_countDF.reset_index(inplace=True)\n",
    "tweet_countDF = tweet_countDF.drop(columns=['username'])\n",
    "\n",
    "trump_countDF = pd.DataFrame.from_dict(trump_countDict, orient='index',columns=['01-2009','02-2009','03-2009','04-2009','05-2009','06-2009','07-2009','08-2009','09-2009','10-2009','11-2009','12-2009',\n",
    "'01-2010','02-2010','03-2010','04-2010','05-2010','06-2010','07-2010','08-2010','09-2010','10-2010','11-2010','12-2010',\n",
    "'01-2011','02-2011','03-2011','04-2011','05-2011','06-2011','07-2011','08-2011','09-2011','10-2011','11-2011','12-2011',\n",
    "'01-2012','02-2012','03-2012','04-2012','05-2012','06-2012','07-2012','08-2012','09-2012','10-2012','11-2012','12-2012',\n",
    "'01-2013','02-2013','03-2013','04-2013','05-2013','06-2013','07-2013','08-2013','09-2013','10-2013','11-2013','12-2013',\n",
    "'01-2014','02-2014','03-2014','04-2014','05-2014','06-2014','07-2014','08-2014','09-2014','10-2014','11-2014','12-2014',\n",
    "'01-2015','02-2015','03-2015','04-2015','05-2015','06-2015','07-2015','08-2015','09-2015','10-2015','11-2015','12-2015',\n",
    "'01-2016','02-2016','03-2016','04-2016','05-2016','06-2016','07-2016','08-2016','09-2016','10-2016','11-2016','12-2016'])\n",
    "trump_countDF.index.name = 'username'\n",
    "trump_countDF.reset_index(inplace=True)\n",
    "trump_countDF = trump_countDF.drop(columns=['username'])\n",
    "\n",
    "clinton_countDF = pd.DataFrame.from_dict(clinton_countDict, orient='index',columns=['01-2009','02-2009','03-2009','04-2009','05-2009','06-2009','07-2009','08-2009','09-2009','10-2009','11-2009','12-2009',\n",
    "'01-2010','02-2010','03-2010','04-2010','05-2010','06-2010','07-2010','08-2010','09-2010','10-2010','11-2010','12-2010',\n",
    "'01-2011','02-2011','03-2011','04-2011','05-2011','06-2011','07-2011','08-2011','09-2011','10-2011','11-2011','12-2011',\n",
    "'01-2012','02-2012','03-2012','04-2012','05-2012','06-2012','07-2012','08-2012','09-2012','10-2012','11-2012','12-2012',\n",
    "'01-2013','02-2013','03-2013','04-2013','05-2013','06-2013','07-2013','08-2013','09-2013','10-2013','11-2013','12-2013',\n",
    "'01-2014','02-2014','03-2014','04-2014','05-2014','06-2014','07-2014','08-2014','09-2014','10-2014','11-2014','12-2014',\n",
    "'01-2015','02-2015','03-2015','04-2015','05-2015','06-2015','07-2015','08-2015','09-2015','10-2015','11-2015','12-2015',\n",
    "'01-2016','02-2016','03-2016','04-2016','05-2016','06-2016','07-2016','08-2016','09-2016','10-2016','11-2016','12-2016'])\n",
    "clinton_countDF.index.name = 'username'\n",
    "clinton_countDF.reset_index(inplace=True)\n",
    "clinton_countDF = clinton_countDF.drop(columns=['username'])\n",
    "\n",
    "sentiment_scoresDF = pd.DataFrame.from_dict(sentiment_scoresDict, orient='index',columns=['01-2009','02-2009','03-2009','04-2009','05-2009','06-2009','07-2009','08-2009','09-2009','10-2009','11-2009','12-2009',\n",
    "'01-2010','02-2010','03-2010','04-2010','05-2010','06-2010','07-2010','08-2010','09-2010','10-2010','11-2010','12-2010',\n",
    "'01-2011','02-2011','03-2011','04-2011','05-2011','06-2011','07-2011','08-2011','09-2011','10-2011','11-2011','12-2011',\n",
    "'01-2012','02-2012','03-2012','04-2012','05-2012','06-2012','07-2012','08-2012','09-2012','10-2012','11-2012','12-2012',\n",
    "'01-2013','02-2013','03-2013','04-2013','05-2013','06-2013','07-2013','08-2013','09-2013','10-2013','11-2013','12-2013',\n",
    "'01-2014','02-2014','03-2014','04-2014','05-2014','06-2014','07-2014','08-2014','09-2014','10-2014','11-2014','12-2014',\n",
    "'01-2015','02-2015','03-2015','04-2015','05-2015','06-2015','07-2015','08-2015','09-2015','10-2015','11-2015','12-2015',\n",
    "'01-2016','02-2016','03-2016','04-2016','05-2016','06-2016','07-2016','08-2016','09-2016','10-2016','11-2016','12-2016'])\n",
    "sentiment_scoresDF.index.name = 'username'\n",
    "sentiment_scoresDF.reset_index(inplace=True)\n",
    "sentiment_scoresDF = sentiment_scoresDF.drop(columns=['username'])\n",
    "\n",
    "trump_sentDF = pd.DataFrame.from_dict(trump_sentDict, orient='index',columns=['01-2009','02-2009','03-2009','04-2009','05-2009','06-2009','07-2009','08-2009','09-2009','10-2009','11-2009','12-2009',\n",
    "'01-2010','02-2010','03-2010','04-2010','05-2010','06-2010','07-2010','08-2010','09-2010','10-2010','11-2010','12-2010',\n",
    "'01-2011','02-2011','03-2011','04-2011','05-2011','06-2011','07-2011','08-2011','09-2011','10-2011','11-2011','12-2011',\n",
    "'01-2012','02-2012','03-2012','04-2012','05-2012','06-2012','07-2012','08-2012','09-2012','10-2012','11-2012','12-2012',\n",
    "'01-2013','02-2013','03-2013','04-2013','05-2013','06-2013','07-2013','08-2013','09-2013','10-2013','11-2013','12-2013',\n",
    "'01-2014','02-2014','03-2014','04-2014','05-2014','06-2014','07-2014','08-2014','09-2014','10-2014','11-2014','12-2014',\n",
    "'01-2015','02-2015','03-2015','04-2015','05-2015','06-2015','07-2015','08-2015','09-2015','10-2015','11-2015','12-2015',\n",
    "'01-2016','02-2016','03-2016','04-2016','05-2016','06-2016','07-2016','08-2016','09-2016','10-2016','11-2016','12-2016'])\n",
    "trump_sentDF.index.name = 'username'\n",
    "trump_sentDF.reset_index(inplace=True)\n",
    "trump_sentDF = trump_sentDF.drop(columns=['username'])\n",
    "\n",
    "clinton_sentDF = pd.DataFrame.from_dict(clinton_sentDict, orient='index',columns=['01-2009','02-2009','03-2009','04-2009','05-2009','06-2009','07-2009','08-2009','09-2009','10-2009','11-2009','12-2009',\n",
    "'01-2010','02-2010','03-2010','04-2010','05-2010','06-2010','07-2010','08-2010','09-2010','10-2010','11-2010','12-2010',\n",
    "'01-2011','02-2011','03-2011','04-2011','05-2011','06-2011','07-2011','08-2011','09-2011','10-2011','11-2011','12-2011',\n",
    "'01-2012','02-2012','03-2012','04-2012','05-2012','06-2012','07-2012','08-2012','09-2012','10-2012','11-2012','12-2012',\n",
    "'01-2013','02-2013','03-2013','04-2013','05-2013','06-2013','07-2013','08-2013','09-2013','10-2013','11-2013','12-2013',\n",
    "'01-2014','02-2014','03-2014','04-2014','05-2014','06-2014','07-2014','08-2014','09-2014','10-2014','11-2014','12-2014',\n",
    "'01-2015','02-2015','03-2015','04-2015','05-2015','06-2015','07-2015','08-2015','09-2015','10-2015','11-2015','12-2015',\n",
    "'01-2016','02-2016','03-2016','04-2016','05-2016','06-2016','07-2016','08-2016','09-2016','10-2016','11-2016','12-2016'])\n",
    "clinton_sentDF.index.name = 'username'\n",
    "clinton_sentDF.reset_index(inplace=True)\n",
    "clinton_sentDF = clinton_sentDF.drop(columns=['username'])\n",
    "\n",
    "positive_sentDF = pd.DataFrame.from_dict(positive_sentDict, orient='index',columns=['01-2009','02-2009','03-2009','04-2009','05-2009','06-2009','07-2009','08-2009','09-2009','10-2009','11-2009','12-2009',\n",
    "'01-2010','02-2010','03-2010','04-2010','05-2010','06-2010','07-2010','08-2010','09-2010','10-2010','11-2010','12-2010',\n",
    "'01-2011','02-2011','03-2011','04-2011','05-2011','06-2011','07-2011','08-2011','09-2011','10-2011','11-2011','12-2011',\n",
    "'01-2012','02-2012','03-2012','04-2012','05-2012','06-2012','07-2012','08-2012','09-2012','10-2012','11-2012','12-2012',\n",
    "'01-2013','02-2013','03-2013','04-2013','05-2013','06-2013','07-2013','08-2013','09-2013','10-2013','11-2013','12-2013',\n",
    "'01-2014','02-2014','03-2014','04-2014','05-2014','06-2014','07-2014','08-2014','09-2014','10-2014','11-2014','12-2014',\n",
    "'01-2015','02-2015','03-2015','04-2015','05-2015','06-2015','07-2015','08-2015','09-2015','10-2015','11-2015','12-2015',\n",
    "'01-2016','02-2016','03-2016','04-2016','05-2016','06-2016','07-2016','08-2016','09-2016','10-2016','11-2016','12-2016'])\n",
    "positive_sentDF.index.name = 'username'\n",
    "positive_sentDF.reset_index(inplace=True)\n",
    "positive_sentDF = positive_sentDF.drop(columns=['username'])\n",
    "\n",
    "negative_sentDF = pd.DataFrame.from_dict(negative_sentDict, orient='index',columns=['01-2009','02-2009','03-2009','04-2009','05-2009','06-2009','07-2009','08-2009','09-2009','10-2009','11-2009','12-2009',\n",
    "'01-2010','02-2010','03-2010','04-2010','05-2010','06-2010','07-2010','08-2010','09-2010','10-2010','11-2010','12-2010',\n",
    "'01-2011','02-2011','03-2011','04-2011','05-2011','06-2011','07-2011','08-2011','09-2011','10-2011','11-2011','12-2011',\n",
    "'01-2012','02-2012','03-2012','04-2012','05-2012','06-2012','07-2012','08-2012','09-2012','10-2012','11-2012','12-2012',\n",
    "'01-2013','02-2013','03-2013','04-2013','05-2013','06-2013','07-2013','08-2013','09-2013','10-2013','11-2013','12-2013',\n",
    "'01-2014','02-2014','03-2014','04-2014','05-2014','06-2014','07-2014','08-2014','09-2014','10-2014','11-2014','12-2014',\n",
    "'01-2015','02-2015','03-2015','04-2015','05-2015','06-2015','07-2015','08-2015','09-2015','10-2015','11-2015','12-2015',\n",
    "'01-2016','02-2016','03-2016','04-2016','05-2016','06-2016','07-2016','08-2016','09-2016','10-2016','11-2016','12-2016'])\n",
    "negative_sentDF.index.name = 'username'\n",
    "negative_sentDF.reset_index(inplace=True)\n",
    "negative_sentDF = negative_sentDF.drop(columns=['username'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timelineDF.to_pickle(\"./RB_timelineDF_090320.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_countDF.to_pickle(\"./RB_tweet_countDF_090320.pkl\")\n",
    "trump_countDF.to_pickle(\"./RB_trump_countDF_090320.pkl\")\n",
    "clinton_countDF.to_pickle(\"./RB_clinton_countDF_090320.pkl\")\n",
    "sentiment_scoresDF.to_pickle(\"./RB_sentiment_scoresDF_090320.pkl\")\n",
    "trump_sentDF.to_pickle(\"./RB_trump_sentDF_090320.pkl\")\n",
    "clinton_sentDF.to_pickle(\"./RB_clinton_sentDF_090320.pkl\")\n",
    "positive_sentDF.to_pickle(\"./RB_positive_sentDF_090320.pkl\")\n",
    "negative_sentDF.to_pickle(\"./RB_negative_sentDF_090320.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unpickled_df = pd.read_pickle(\"./negative_sentDF_090320.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "tweet_countDF.mean().plot(kind='line', color='green', figsize=(15,8),title='Mean Monthly Tweet Volume - Random Baseline Users')\n",
    "# plt.legend(('Trump','Hillary'))\n",
    "plt.ylabel('Mean Monthly Tweet Count')\n",
    "plt.xlabel('Timeline')\n",
    "plt.savefig('RB_graphics/rb_tweetcount.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "trump_countDF.mean().plot(kind='line', color='red', figsize=(15,8),title='Mean Monthly Trump/Hillary Mention Count - Random Baseline Users')\n",
    "clinton_countDF.mean().plot(kind='line', color='blue', figsize=(15,8))\n",
    "plt.legend(('Trump','Hillary'))\n",
    "plt.ylabel('Mean Monthly Mentions')\n",
    "plt.savefig('RB_graphics/rb_mentions.png')\n",
    "plt.xlabel('Timeline')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "sentiment_scoresDF.mean().plot(kind='line', color='green', figsize=(15,8),title='Sentiment Analysis - Random Baseline Users')\n",
    "trump_sentDF.mean().plot(kind='line', color='red', figsize=(15,8))\n",
    "clinton_sentDF.mean().plot(kind='line', color='blue', figsize=(15,8))\n",
    "plt.legend(('General Tweets','Tweets Mentioning Trump','Tweets Mentioning Hillary'))\n",
    "plt.axhline(0, color=\"grey\", linestyle=\"--\")\n",
    "plt.ylabel('Mean Monthly Sentiment')\n",
    "plt.savefig('RB_graphics/rb_sentiment.png')\n",
    "plt.xlabel('Timeline')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
